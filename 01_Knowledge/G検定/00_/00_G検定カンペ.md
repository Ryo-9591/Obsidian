# AIの誕生

| 項目                                             | 説明                                                                       | 例                           |
| ---------------------------------------------- | ------------------------------------------------------------------------ | --------------------------- |
| レベル1<br><font color="#eeece1">ルールベースAI</font>  | すべての振る舞いがあらかじめ決められている<br>シンプルな制御システム                                     | エアコン、自動販売機                  |
| レベル2<br>古典的AI                                  | 探索・推論・知識データを用いて、<br>状況に応じた振る舞い                                           | 将棋やチェスのAI<br>エキスパートシステム     |
| レベル3<br><font color="#ffff00">機械学習AI</font>    | <font color="#eeece1">非常に多くのサンプルデータをもとに、<br>入力と出力の関係を学習するシステム</font><br> | レコメンデーションシステム<br>迷惑メールフィルター |
| レベル4<br><font color="#ffff00">ディープラーニング</font> | データから特徴量を自律的に学習する、<br>より高度なシステム                                          | 顔認証　音声認識　画像生成AI             |

| 年    | 内容                                                                                                                                                                                      |
| ---- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1946 | 世界初の汎用電子計算機<font color="#ffff00">エニアック(ENIAC) </font>誕生                                                                                                                                 |
| 1956 | ダートマス会議<br>①人工知能という言葉が<font color="#ffff00">ジョン・マッカーシー</font>によって初めて使用<br>②ハーバート・サイモン、アレン・ニューウェル、クリフ・ショーの数学の定理を自動的に証明する初期のAIプログラム<font color="#ffff00">ロジック・セオリスト</font> デモンストレーション<br> |

# 強いAIと弱いAIの提唱（ジョンサール）

| 項目   | 説明                    | 例        |
| ---- | --------------------- | -------- |
| 強いAI | 汎用的人工知能               | 自我を持ったAI |
| 弱いAI | 特化型人工知能<br>→中国語の部屋などで | AlphaGo  |

# 第一次AIブーム（1950年代後半〜1960年代）
<font color="#ffff00">トイ・プロブレム</font>（パズルや迷路探索といった限られた問題）で成果を上げる
現実世界の複雑な情報や未知の状況を扱うことができない<font color="#ffff00">フレーム問題</font>（1969）に直面

| 項目                                | 内容                                                                                                           |
| --------------------------------- | :----------------------------------------------------------------------------------------------------------- |
| ハノイの塔                             | ルール<br>1.  一度に一つの円盤しか動かせない。<br>2. 小さい円盤の上に大きい円盤を乗せてはいけない。<br>3. 3本ある杭のどれを使ってもよい。<br>最小手数で解くには、2n−1回の手数が必要となる |
| STRIPS                            | 前提・行動・結果を記述するプランニング                                                                                          |
| 1968～1970年<br>SHRDLU（テリー・ウィノグラード） | プランニングを「積み木の世界」で完全再現<br>自然言語だけで積み木を作れた                                                                       |
| 1984年<br>Cycプロジェクト（ダグ・レナート）       | 常識を記号の形で表現し、それを基にコンピュータが論理的な推論を行えるようにすることを目指す                                                                |


# ボードゲームパターン数

| ゲーム | パターン数  |
| --- | ------ |
| オセロ | 10^60  |
| チェス | 10^120 |
| 将棋  | 10^220 |
| 囲碁  | 10^360 |

# 探索アルゴリズム

|             |                                                                      | 図                                    |
| ----------- | -------------------------------------------------------------------- | ------------------------------------ |
| 幅優先探索       | 根から近いノードから順に探索<br>すべてのノードをキューに保持する必要がある<br>→メモリ不足になる                 | ![[Pasted image 20250901174929.png]] |
| 深さ優先探索      | 根からできるだけ深く探索<br>一度に一つの経路上のノードだけを記憶すればよい<br>→メモリ不足になりにくい<br>          | ![[Pasted image 20250901174941.png]] |
| Mini-Max法   | 相手も自分も最善を尽くすという前提で、ゲームのすべての可能な局面をツリー状に展開し、最終的な評価値が最大（ミニ）になるような手を選ぶ方法 | ![[Pasted image 20250901105639.png]] |
| Alpha-Beta法 | ミニマックス法を改良したもので、明らかに不利な局面の探索を途中で打ち切る                                 | ![[Pasted image 20250901105752.png]] |
| ヒューリスティック探索 | ヒューリスティクスを使って、より効率的に探索を進める方法                                         |                                      |
| モンテカルロ木探索   | ランダムな試行（シミュレーション）を繰り返して、最も有望な手を見つけ出します。                              |                                      |

## AI効果
かつて人工知能（AI）だと考えられていた技術が、普及して当たり前になると、もはやAIとはみなされなくなる現象
## 1950年：チューリングテスト（アラン・チューリング）
機械が人間と同等の知的振る舞いを示せるかを判定するためのテスト
## 1991年：ローブナーコンテスト（Loebner Prize） 
 チューリングテストの実践版として始まった年次コンテスト
## 1966年：イライザ（ELIZA） （ジョセフ・ワイゼンバウム） 人工無能
初期の対話プログラムです。キーワードに反応して質問を返すという単純な仕組み
イライザ効果：イライザを人間と勘違いする現象
## 身体性
知能獲得するには<font color="#ffff00">身体が不可欠</font>とする考え方
## 2045年：シンギュラリティ（レイ・カーツワイル）
AIが自らより優れたAIを開発し、そのAIがさらに優れたAIを開発するという「知能の爆発的連鎖」が起こることで、人類の知性を超える超知能（Superintelligence）が誕生するという考え

# 第二次AIブーム（1980年代〜）
知識獲得のボトルネック・シンボルグラウンディング問題
## エキスパートシステム
知識ベースと推論エンジンにより構成

| 名前      | 年    | 開発者            | 説明                                                                               |
| ------- | ---- | -------------- | -------------------------------------------------------------------------------- |
| DENDRAL | 1960 | エドワード・ファイゲンバウム | 質量スペクトルデータから、未知の有機化合物の分子構造を推定するシステム。専門家が利用する「ヒューリスティック（発見的手法）」をルール化して組み込んだ。      |
| MYCIN   | 1970 | スタンフォード大学      | 血液感染症の原因菌を特定し、治療薬を推奨するシステム。不確実な情報（発熱、症状など）から確率的に推論を行う「**確信度係数**」の概念を導入したことで知られる。 |
# オントロジー
意味ネットワークなどで用いられる知識の結び付け方の規則

| オントロジー種類       | 内容                                            |
| -------------- | --------------------------------------------- |
| ライトウェイト・オントロジー | 概念の分類（タクソノミー）や単純な語彙関係に焦点を当てた、比較的単純な構造のオントロジー。 |
| ヘビーウェイト・オントロジー | 複雑な概念間の関係性や制約、論理的な推論ルールを詳細に記述する、複雑な構造のオントロジー。 |

| 関連出来事      | 年    | 内容                                                                     |
| ---------- | ---- | ---------------------------------------------------------------------- |
| Cycプロジェクト  | 1984 | 人間のすべての一般常識をデータベース化し、知識ベースを構築することで人間と同等の推論システムを目指しました 。                |
| セマンティックウェブ |      | ウェブ上のデータをコンピュータが理解・解釈できるようにするための技術や概念の総称。オントロジーは、このセマンティックウェブの中核技術の一つ。 |
| ワトソン（IBM）  | 2011 | アメリカのクイズ番組ジョパディーで勝利(ライトオントロジーを使用)<br>質問に対して高速で検索しているだけ                 |
| 東ロボ君       | 2011 | 東京大学の合格を目指すも意味理解に苦しみ凍結                                                 |
# 第三次AIブーム（2000年代後半〜現在） 機械学習・特徴表現学習の時代


# 教師あり学習

# アンサンブル学習
## バギング
複数のモデルを独立して学習させ、それらの予測結果を統合
## ブースティング
複数の弱い学習器（性能の低いモデル）を直列につなぎ、前のモデルが間違えたデータに重みを付けて学習（<font color="#ffff00">AdaBoost</font>）
バギングより逐次的に学習を進めるので時間がかかる
### 勾配ブースティング (Gradient Boosting)
AdaBoostとは異なる方法で弱点を克服します。
<font color="#ffff00">予測誤差</font>（残差）を最小化するように、次のモデルを学習させます。
これは、<font color="#ffff00">勾配降下法を応用したアプローチ</font>です。
### XGBoost (eXtreme Gradient Boosting)
XGBoostは、勾配ブースティングをさらに進化させた、高性能なアルゴリズムです。
その最大の強みは速度と精度
- **高速性**: 効率的なデータ探索と並列処理によって、学習速度が非常に速い。
- **高精度**: 過学習を防ぐための**L1/L2正則化**を導入しており、高い予測精度を誇る。


# サポートベクターマシン（SVM）
・データを最も効率的に分ける決定境界を見つけることで、分類や回帰を行う教師あり学習モデル
・異なるクラスのデータ点を分離する際に、決定境界と、それに最も近いデータ点（**サポートベクター**）との間の距離（**マージン**）を最大化することを目指す
・過学習を防ぎ、未知のデータに対する高い予測精度を実現します。
・線形分離できないデータを扱うため、SVMはカーネル法という手法を用います。
### カーネル関数
データをより高次元の空間にマッピングすることで、低次元では分離不可能だったデータが線形で分離できるようにします。
### カーネルトリック
高次元空間での計算は非常に複雑になりますが、SVMは**カーネルトリック**を用いることで、実際に高次元にマッピングすることなく、**元の低次元空間での計算**によって、高次元空間での内積を効率的に求める

---
# 自己回帰モデル
<font color="#ffff00">時系列データ分析</font>で使われるモデルで、過去のデータを使って未来の値を予測する手法
## ベクトル自己回帰モデル（VARモデル）
<font color="#ffff00">複数の時系列データ</font>間の相互依存関係を分析・予測するための統計モデル