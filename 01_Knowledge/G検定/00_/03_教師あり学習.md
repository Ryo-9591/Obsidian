# 線形回帰
![[Pasted image 20250901130153.png]]
## 単回帰
1つの説明変数を使って、1つの目的変数を予測する手法
## 重回帰
2つ以上の説明変数を使って、1つの目的変数を予測する手法

# 分類問題
## ロジスティクス回帰
### シグモイド関数
2クラス分類が得意
![[Pasted image 20250901132935.png]]
### ソフトマックス関数
多クラス分類が得意
![[Pasted image 20250901133226.png]]
### ランダムフォレスト
それぞれの決定木に対してランダムに一部取り出して学習を取り出すのを<font color="#ffff00">ブーストラップサンプリング</font>
![[Pasted image 20250901133543.png]]

---

---
# サポートベクターマシン（SVM）
・データを最も効率的に分ける決定境界を見つけることで、分類や回帰を行う教師あり学習モデル
・異なるクラスのデータ点を分離する際に、決定境界と、それに最も近いデータ点（**サポートベクター**）との間の距離（**マージン**）を最大化することを目指す
・過学習を防ぎ、未知のデータに対する高い予測精度を実現します。
・線形分離できないデータを扱うため、SVMはカーネル法という手法を用います。
### カーネル関数
データをより高次元の空間にマッピングすることで、低次元では分離不可能だったデータが線形で分離できるようにします。
### カーネルトリック
高次元空間での計算は非常に複雑になりますが、SVMは**カーネルトリック**を用いることで、実際に高次元にマッピングすることなく、**元の低次元空間での計算**によって、高次元空間での内積を効率的に求める

---
# 自己回帰モデル
<font color="#ffff00">時系列データ分析</font>で使われるモデルで、過去のデータを使って未来の値を予測する手法
## ベクトル自己回帰モデル（VARモデル）
<font color="#ffff00">複数の時系列データ</font>間の相互依存関係を分析・予測するための統計モデル
