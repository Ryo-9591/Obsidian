# RNN
隠れ層にリカレント結合を持ち、前の時刻の隠れ層の状態（情報）が、次の時刻の隠れ層の入力として渡される
→<font color="#ffff00">単語の並びや音声</font>、株価の推移といった時間的な文脈を持つデータを学習することができる
## RNNが直前の隠れ層の状態しか記憶できないという課題を克服

| 項目          | 特徴                                       | 図                                    |
| ----------- | ---------------------------------------- | ------------------------------------ |
| エルマンネットワーク  | 直前の隠れ状態を次の層の入力に<br><br>直前の文脈を考慮するタスク     | ![[Pasted image 20250901202322.png]] |
| ジョルダンネットワーク | 直前の最終的な出力を次の層の入力に<br><br>過去の行動履歴を考慮するタスク | ![[Pasted image 20250901202339.png]] |

## 勾配消失問題を克服

| モデル名                                 | 特徴  | 構造とゲート | メリット/デメリット |
| ------------------------------------ | --- | ------ | ---------- |
| **LSTM**<br>(Long Short-Term Memory) |     |        |            |
| GRU<br>(Gated Recurrent Unit)        |     |        |            |
