# 機械学習の具体的な手法
## 第1次AIブーム：探索と推論
### 探索木
![[Pasted image 20250901100707.png]]
#### 幅優先探索
<font color="#ffff00">最短距離でゴールにたどり着く解</font>を見つける
→探索中のすべてのノードをキューに保持する必要があるので、<font color="#ffff00">メモリ不足</font>になる
#### 深さ優先探索
順番に深く探りゴールを見つけたら終了するので、<font color="#ffff00">最短距離であるかは保証しない</font>
→一度に一つの経路上のノードだけを記憶すればよいため、<font color="#ffff00">メモリ不足になりにくい</font>

## ハノイの塔

![[Pasted image 20250901101655.png]]

### ルール
1.  一度に一つの円盤しか動かせない。
2. 小さい円盤の上に大きい円盤を乗せてはいけない。
3. 3本ある杭のどれを使ってもよい。

<font color="#ffff00">最小手数で解くには、2n−1回の手数が必要となる</font>

---
# ロボットの行動計画（プランニング）

<font color="#ffff00">前提・行動・結果</font>を記述する<font color="#ffff00">STRIPS</font>をすればプランニングできる
## 1968～1970年：SHRDLU（テリー・ウィノグラード）
プランニングを「積み木の世界」で完全再現
→<font color="#ffff00">Cycプロジェクト</font>に貢献
## 1984年：Cycプロジェクト（ダグ・レナート）
常識を記号の形で表現し、それを基にコンピュータが論理的な推論を行えるようにすることを目指す

---
# ボードゲーム
## 2016年：AlphaGo（DeepMind）
囲碁世界王者に勝利

| ゲーム | パターン数  |
| --- | ------ |
| オセロ | 10^60  |
| チェス | 10^120 |
| 将棋  | 10^220 |
| 囲碁  | 10^360 |

## 従来のAIと囲碁
### Mini-Max法
相手も自分も最善を尽くすという前提で、ゲームのすべての可能な局面をツリー状に展開し、最終的な評価値が最大（ミニ）になるような手を選ぶ方法
![[Pasted image 20250901105639.png]]
### Alpha-Beta法
ミニマックス法を改良したもので、明らかに不利な局面の探索を途中で打ち切る
![[Pasted image 20250901105752.png]]
## AlphaGoの革新的なアプローチ
### モンテカルロ木探索（MCTS）+ ディープラーニング
シミュレーション（<font color="#ffff00">プレイアウト</font>）を繰り返し、統計的に最も有望な手を見つける手法

---
##  第二次AIブーム：知識表現
### 人工無能
#### 1966年：イライザ（ELIZA） （ジョセフ・ワイゼンバウム）
イライザ効果：イライザを人間と勘違いする現象
### エキスパートシステム
#### 1960年：DENDRAL（エドワード・ファイゲンバウム）
有機化合物特定プログラム
#### 1970年：MYCIN（スタンフォード大学）
血液のバクテリアの診断支援をするルールベースプログラム

###  1984年：Cycプロジェクト（ダグラス・レナート）
人間の常識をコンピュータが理解できるように、<font color="#ffff00">オントロジー</font>を構築することを目指す
#### オントロジー（概念化の明示的な仕様）
##### ライトウェイト・オントロジー
完全に正しくなくても使えるものであればいい
<font color="#ffff00">ウェブマイニング（webを探って知識を取りだす）</font>・<font color="#ffff00">データマイニング（ビックデータを使って知識を取り出す）</font>に使用
### 2011年：ワトソン（IBM）
アメリカのクイズ番組ジョパディーで勝利(ライトオントロジーを使用)
質問に対して高速で検索しているだけ
### 2011年：東ロボ君
東京大学の合格を目指すも意味理解に苦しみ凍結
##### ヘビーウェイト・オントロジー
意味的な関係の正当性を考察が必要

---
## 第3次AIブーム：機械学習・特徴表現学習

### 機械学習
レコメンデーションシステム、スパムフィルタ
#### 統計的自然言語処理
複数の単語をひとまとまりにした単位を対話データ(<font color="#ffff00">コーパス</font>)を用いて推測

### ディープラーニング

と

## 3. ディープラーニングの基礎技術と数理的側面

### 3.1 ニューラルネットワークの基本構造

ディープラーニングは、ニューラルネットワークを多層に重ねた構造が特徴です。

- **ニューロン（ノード）**: 情報を処理する最小単位。複数の入力信号を受け取り、1つの出力信号を生成します。
    
- **層（Layer）**: 複数のニューロンが集まった単位。**入力層**、**隠れ層**、**出力層**があります。
    
- **重み（Weight）とバイアス（Bias）**: 重みは入力信号の重要度を、バイアスはニューロンが活性化する閾値を調整するパラメータで、学習によって最適化されます。
    
- **活性化関数（Activation Function）**: 入力信号の総和を出力信号に変換し、非線形性を導入することで複雑なパターンを学習できるようにします。
    

---

### 3.2 活性化関数と最適化手法

ディープラーニングの学習に不可欠な要素です。

#### 活性化関数

- **シグモイド関数 (Sigmoid Function)**: 入力値を0から1の間に変換し、確率として解釈したい場合に有用です。
    
- **ReLU (Rectified Linear Unit)**: 入力値が正ならそのまま、負なら0を出力します。計算が高速で、**勾配消失問題**を抑制できるため、隠れ層で最も広く使われています。
    

#### 最適化手法

- **勾配降下法 (Gradient Descent)**: 損失関数（予測と正解の誤差）が最小になるように、モデルのパラメータを少しずつ調整するアルゴリズムです。
    
- **確率的勾配降下法 (SGD: Stochastic Gradient Descent)**: すべてのデータではなく、ランダムに選んだ一部のデータ（**ミニバッチ**）を用いてパラメータを更新するため、大規模データでも効率的です。
    
- **Adam (Adaptive Moment Estimation)**: SGDの進化版で、収束が高速かつ安定しており、多くのケースで最初に試すべき手法とされています。
    

**勾配降下法と誤差逆伝播法の関係性** **勾配降下法**は「損失を最小化する」という**目的**を示し、**誤差逆伝播法（Backpropagation）**はその目的のために「各パラメータの勾配を効率的に計算する」という**手段**を提供します。

---

### 3.3 評価指標とモデルの性能評価

回帰問題の評価には、主に予測値と実測値の差を測る以下の指標が用いられます。

- **平均絶対誤差（MAE: Mean Absolute Error）**: 予測誤差の絶対値の平均。外れ値の影響を受けにくいのが特徴です。 MAE=n1​∑i=1n​∣yi​−y^​i​∣
    
- **平均二乗誤差（MSE: Mean Squared Error）**: 予測誤差の二乗の平均。誤差が大きいほどペナルティが大きくなるため、外れ値に敏感です。 MSE=n1​∑i=1n​(yi​−y^​i​)2
    
- **二乗平均平方根誤差（RMSE: Root Mean Squared Error）**: MSEの平方根。誤差の単位が元の実測値と同じで解釈が容易です。 RMSE=n1​∑i=1n​(yi​−y^​i​)2![](data:image/svg+xml;utf8,<svg%20xmlns="http://www.w3.org/2000/svg"%20width="400em"%20height="1.88em"%20viewBox="0%200%20400000%201944"%20preserveAspectRatio="xMinYMin%20slice"><path%20d="M983%2090
    l0%20-0
    c4,-6.7,10,-10,18,-10%20H400000v40
    H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
    s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
    c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
    c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
    c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
    c53.7,-170.3,84.5,-266.8,92.5,-289.5z
    M1001%2080h400000v40h-400000z"></path></svg>)​
    

---

## 4. 主要なディープラーニングモデルと応用分野

### 4.1 画像認識・物体検出：CNNと代表モデル

**畳み込みニューラルネットワーク（CNN: Convolutional Neural Network）**は、画像データ処理に特化したニューラルネットワークです。

- **仕組み**: **畳み込み層**で画像をスライドする**フィルター**を使って特徴を抽出し、**プーリング層**で次元削減を行います。これにより、画像内の対象物の位置がずれても認識が可能になります。
    
- **代表的なモデル**:
    
    - **ResNet（Residual Network）**: **スキップ接続**を導入し、深いネットワークの学習を可能にしました。
        
    - **YOLO (You Only Look Once)**: 物体領域の切り出しと認識を同時に行い、リアルタイムでの高速な物体検出を実現しました。
        

---

### 4.2 自然言語処理：Transformer、BERT、GPT

**Transformer**は、**Attention機構**の導入により、長距離の依存関係を効率的に学習できるようになった画期的なモデルです。

- **Attention機構**: 入力データ内の重要な部分に注目し、重み付けを行う仕組みです。特に**Self-Attention**が文脈理解の鍵となります。
    

**BERTとGPTの比較** | モデル名 | 特徴 | 強み | | :--- | :--- | :--- | | **BERT** | Transformerの**エンコーダ**を使用。文章を**双方向**から学習します。 | 質問応答や文章分類といった**解析タスク**に優れています。 | | **GPT** | Transformerの**デコーダ**を使用。文章を**一方向**から学習します。 | 新しい文章や応答を作成する**生成タスク**に強みがあります。 |

---

### 4.3 生成モデル：GAN, VAE, Diffusion Model

生成AIは、新しいコンテンツを生成する技術の総称です。

- **敵対的生成ネットワーク（GAN: Generative Adversarial Networks）**: **生成器（Generator）**と**識別器（Discriminator）**という2つのネットワークを競い合わせることで学習します。非常に高品質な画像を生成できますが、学習が不安定になりやすいという課題があります。
    
- **変分オートエンコーダ（VAE: Variational Autoencoder）**: データの潜在空間をモデル化するアプローチ。学習は安定していますが、GANに比べて生成画像がぼやけやすい傾向があります。
    
- **Diffusion Model**: ノイズを徐々に加えていく**拡散過程**と、ノイズからデータを再構築する**逆拡散過程**を学習します。GANに匹敵する高品質な画像を生成でき、学習も安定しているため、現在主流のモデルです。
    

---

## 5. AIの社会実装とプロジェクト管理

### 5.1 AI開発プロセスと概念実証（PoC）

AI開発の成功には、本格的な開発前に技術的・ビジネス的な実現可能性を検証する**概念実証（PoC: Proof of Concept）**が不可欠です。PoCの主な目的は、リスクを最小化し、実現が困難な場合は早期に開発を中止する決断を下すことです。

---

### 5.2 MLOps, DevOps, AIOpsの概念と相互関係

AIをビジネスで活用する際には、開発・運用プロセスを効率化するための概念が重要です。

- **DevOps (Development + Operations)**: ソフトウェア開発と運用を連携させる概念。
    
- **MLOps (Machine Learning + Operations)**: DevOpsの考え方を機械学習に特化させたもので、モデルの開発から運用、再学習までの一連のライフサイクルを管理します。AIを「つくる」側の概念です。
    
- **AIOps (AI for IT Operations)**: ITシステムの運用にAIを適用し、自動化や効率化を図る概念。AIを「つかう」側の概念です。
    

---

## 6. AI活用における法的・倫理的課題

### 6.1 AI倫理・ガバナンス：新シラバスの重要項目

最新のG検定シラバスでは、AIの社会実装における倫理的課題が重視されています。**JDLA**が定める倫理原則には、**プライバシー**、**公平性**、**透明性（XAI）**、**悪用防止**などが含まれます。

---

### 6.2 著作権法：AI生成物と法制度の最前線

AI生成物の著作権については、法的な議論が活発に行われています。

- **著作物の定義**: 著作権法は、人間の「**思想又は感情を創作的に表現したもの**」を著作物とします。
    
- **AI生成物の著作権の有無**: AIには人間の「思想又は感情」がないため、AIが自律的に生成した創作物は、原則として著作物として認められません。しかし、人がAIを道具として使い、そこに「**創作意図**」や「**創作的寄与**」が認められる場合は、その創作物は著作物と判断され、AIを利用した人が著作者となると考えられています。
    
- **著作権法第30条の4**: AIの学習を目的としたデータ利用は、著作権者の利益を不当に害しない限り、著作権者の許諾なく利用できるとされています。
    

---

### 6.3 個人情報保護法とGDPR

AI開発における個人情報の取り扱いに関する法的知識も不可欠です。

- **個人情報保護法**: 2022年の改正により、個人の権利が拡大し、事業者の責務が強化されました。AI開発を促進するために、個人を識別できないように加工された情報の利用を緩和する「**仮名加工情報制度**」が創設されました。
    
- **GDPR (General Data Protection Regulation)**: EUにおける厳格な個人情報保護規則です。EU域外へのデータ移転には、データ保護の水準がEUと同等であると認められる「**十分性認定**」が必要です。