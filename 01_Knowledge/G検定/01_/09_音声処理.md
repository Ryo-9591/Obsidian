# A-D変換
アナログ音声信号をデジタルデータに変換するプロセス
## PCM（パルス符号変調）
アナログ信号を一定間隔でサンプリング
→デジタルデータに量子化
→ビット列に変換
# 高速フーリエ変換 (FFT) 
デジタル化された音声信号は、時間的な波形だけでは分析が困難
→FFTは、<font color="#ffff00">時間領域の信号を周波数領域に変換するアルゴリズム</font>
どの周波数の音がどれくらいの強さで含まれているかを可視化
この周波数スペクトルの滑らかな輪郭が<font color="#ffff00">スペクトル包絡</font>
# フォルマント と フォルマント周波数
スペクトル包絡上に現れる、特にエネルギーが集中している周波数のピークが<font color="#ffff00">フォルマント</font>、ピークの周波数が<font color="#ffff00">フォルマント周波数</font>
# メル尺度 と メル周波数ケプストラム係数 (MFCC)
人間の聴覚が感じる音の高さ（ピッチ）をモデル化した<font color="#ffff00">非線形的な尺度</font>
MFCCは、この<font color="#ffff00">メル尺度に基づいてスペクトル包絡の特徴を抽出・圧縮したもの</font>

音韻 と 音素
音韻は、ある言語における音の体系や規則です。音素は、この音韻の概念に基づいて定義された、意味を区別する最小の音声単位です（例：日本語の「カ」「キ」「ク」）。

隠れマルコフモデル (HMM) と 音声認識エンジン
HMMは、音声認識の黎明期から主流であった確率モデルです。音声信号から最も可能性の高い音素の並びを推測します。このHMMを中核としたシステム全体が、当時の音声認識エンジンでした。

CTC (Connectionist Temporal Classification)
RNNなどのニューラルネットワークモデルと組み合わせて使用される損失関数です。音声認識では入力と出力の長さが異なることが多いため、CTCはアライメント（音声と文字の対応付け）を自動的に学習し、モデルの訓練を効率化します。

WaveNet
Googleが開発した音声合成に特化したニューラルネットワークモデルです。テキストから音声の波形を直接生成することで、人間のように自然な音声を合成できます。

話者識別
音声信号そのものを分析して、それが誰の声であるかを特定する技術です。音声内容ではなく、声の特徴（声質、発音の癖など）に注目します。