# CNN
ディープラーニングの中で最も成功しているモデル
## 物体認識・画像分類タスクに使われるCNN

| 項目           | 年代    | 人物                 | 説明                                                                                                                               | 図                                    |
| ------------ | ----- | ------------------ | -------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------ |
| ネオコグニトロン     | 1979年 | 福島邦彦               | 階層的な特徴抽出と位置ずれ不変性<br>S細胞：特徴を抽出する役割<br>C細胞：S細胞層で抽出された特徴の位置のずれを吸収                                                                   | ![[Pasted image 20250901190743.png]] |
| LeNet        | 1998年 | ヤン・ルカン             | <font color="#ffff00">手書き数字の認識に使用</font><br><br>畳み込み層とプーリング層を組み合わせることで画像の特徴を効率的に抽出<br><font color="#ffff00">誤差逆伝搬法</font>を用いる    | ![[Pasted image 20250901191054.png]] |
| AlexNet      | 2012年 | アレックス・クリジェフスキー     | ILSVRC優勝<br>大規模画像データセットImageNetでの圧倒的な性能<br>GPUの活用、<font color="#ffff00">ReLU</font>、ドロップアウトを導入                                   | ![[Pasted image 20250901191937.png]] |
| GoogleNet    | 2014年 | Google             | ILSVRC優勝<br><font color="#ffff00">Inceptionモジュール</font>を導入し、複数の畳み込み層を並列に処理することで、計算量を増やさずに精度を向上                                   | ![[Pasted image 20250901192258.png]] |
| VGG          | 2014年 | オックスフォード大学         | 同じサイズの小さな<font color="#ffff00">3x3</font>の畳み込み層を何層も重ねることで、表現力を高めた                                                                | ![[Pasted image 20250901192319.png]] |
| ResNet       | 2015年 | Microsoft Research | <font color="#ffff00">Residual Block</font>（残差ブロック）を導入<br>深いネットワークの学習を困難にしていた<font color="#ffff00">勾配消失問題</font>を解決              | ![[Pasted image 20250901192330.png]] |
| Wide ResNet  | 2016年 | セルゲイ・ザハロフ          | ResNetの残差ブロックの幅（チャネル数）を広げることで、パラメータ数を大幅に増やさずに性能を向上                                                                               | ![[Pasted image 20250901192656.png]] |
| DenseNet     | 2017年 | Gao Huang          | 密な接続（Dense Connectivity）を導入<br><font color="#ffff00">各層が、それより前の全ての層の出力に接続</font>することで、特徴の再利用を促進し、勾配の伝播を改善した。                     | ![[Pasted image 20250901192727.png]] |
| SENET        | 2017年 | Momenta            | ILSVRC優勝<br>SE（Squeeze-and-Excitation）ブロックを導入<br><font color="#ffff00">チャネル方向の情報を動的に重み付け</font>することで、重要な特徴を強調し、精度を向上             | ![[Pasted image 20250901192834.png]] |
| MobileNet    | 2017年 | Google             | <font color="#ffff00">Depthwise Separable Convolution</font>を導入し、計算量を大幅に削減。モバイルデバイスや組み込みシステムでの利用に適した軽量なモデル。                      | ![[Pasted image 20250901193514.png]] |
| NASNet       | 2018年 | Google             | Neural Architecture Search（NAS）を用いて、強化学習によって最適なネットワーク構造を自動で探索した最初のモデル                                                            | ![[Pasted image 20250901193631.png]] |
| MnasNet      | 2018年 | Google             | NASNetを改良し、モバイルデバイスのレイテンシ（遅延）を考慮してネットワーク構造を探索。実用的なパフォーマンスと効率を両立した。                                                               |                                      |
| EfficientNet | 2019年 | Google             | 深さ（depth）、幅（width）、解像度（resolution）の3つの次元をバランス良くスケーリングする<font color="#ffff00">複合スケーリング</font>を提案<br>パラメータ数が少ないけど精度がいい<br>→転移学習に有用 | ![[Pasted image 20250901193745.png]] |
## 物体検出タスクに使われるCNN
### 2段階アプローチ
①画像から物体が存在しそうな領域（領域候補）を抽出する。
②抽出された各領域をCNNで分類・位置調整する。
特徴・・・高精度だが、処理速度は遅め。
### 1段階アプローチ
画像全体を一度に処理し、物体の位置とクラスを同時に予測する。
特徴:・・・高速だが、精度は2段階アプローチに劣ることがあった

| 項目                                  | 年代    | 人物            | 説明                                                                                                                                                              | アプローチ    |
| ----------------------------------- | ----- | ------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------- |
| R-CNN                               | 2014年 | Ross Girshick | 領域提案 (Region Proposal) とCNNによる特徴抽出を組み合わせた最初の成功モデル<br>画像から物体候補領域を2,000個抽出(Selective Search)し、各領域をCNNで分類することで、高い精度を実現したが、<font color="#ffff00">処理速度が遅いのが課題</font> | 2段階アプローチ |
| Fast R-CNN                          | 2015年 | Ross Girshick | R-CNNの改良版。画像全体に対して一度だけCNNを適用し、その特徴マップから各領域の特徴を抽出することで、処理速度を大幅に向上<br><font color="#ffff00">FPN</font>(Feature Pyramid Network)がこのモデルに組み込まれ、様々なスケールの物体検出精度が向上     | 2段階アプローチ |
| YOLO (You Only Look Once)           | 2016年 | Joseph Redmon | 1回の推論で、画像のグリッドセルごとに物体の位置とクラスを同時に予測<br>従来の2段階アプローチ（領域提案→分類）と異なり、<font color="#ffff00">非常に高速な処理が可能</font>                                                         | 1段階アプローチ |
| SSD (Single Shot MultiBox Detector) | 2016年 | Wei Liu       | YOLOと同様に1段階のモデルですが、異なるスケールの特徴マップを利用することで、様々なサイズの物体を効率的に検出します。                                                                                                   | 1段階アプローチ |
| Mask R-CNN                          | 2017年 | Kaiming He    | Faster R-CNNを拡張し、物体検出に加えてセグメンテーション（物体の輪郭をピクセル単位で識別）のタスクも同時に実行できるようにしました。                                                                                        | 2段階アプローチ |
| RetinaNet                           | 2017年 | Tsung-Yi Lin  | Focal Lossを導入し、前景（物体）と背景（物体でない）のアンバランスなデータ分布による学習の課題を解決しました。これにより、1段階の検出器でも高い精度を達成                                                                              | 1段階アプローチ |
| EfficientDet                        | 2019年 | Mingxing Tan  | EfficientNetをバックボーンに利用し、<font color="#ffff00">BiFPN (Bi-directional Feature Pyramid Network)</font>で特徴を融合。高い精度と効率性を両立させ、最先端のモデルとなりました。                          | 1段階アプローチ |
## セグメンテーションタスクに使用されるCNN
### セグメンテーションタスクの種類

| タスク名        | 概要                                         | 目的と出力                                                               | 代表的なモデル                                                   |
| ----------- | ------------------------------------------ | ------------------------------------------------------------------- | --------------------------------------------------------- |
| セマンティック     | 画像内の全てのピクセルを<br>事前に定義されたカテゴリ（例: 車、道路、空）に分類 | 画像内の各ピクセルがどのカテゴリに属するかを識別<br>同じカテゴリの物体は区別しない                         | FCN (Fully Convolutional Network)<br>U-Net<br>DeepLabシリーズ |
| インスタンス      | 同じカテゴリに属する個々の物体を区別しながら、ピクセル単位で分類           | 同じカテゴリ内の各インスタンス（個体）を異なる色などで識別し、個々の物体の正確な輪郭を特定                       | Mask R-CNN                                                |
| パノプティック<br> | セマンティック＋インスタンス                             | 数えられる物体、例: 人、車と<br>数えられない領域、例: 空、道路<br>の両方を識別<br>画像全体を統一的にセグメンテーション | Panoptic FPN<br>UPSNet                                    |
![[Pasted image 20250901195854.png]]

| モデル名    | 主な特徴と技術                                                                                                                                                                      |
| ------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| U-Net   | エンコーダー・デコーダー構造とスキップ接続が特徴<br>エンコーダーで画像を圧縮して高次特徴を抽出し<br>デコーダーで空間的な情報を復元<br><br>スキップ接続により、高解像度の特徴を直接デコーダーに伝達し、<br>細かい物体の輪郭を正確に捉えることを可能に                                         |
| PSPNet  | Pyramid Scene Parsingという手法を導入<br>画像全体を複数の異なるスケールでプールし、その結果を統合することで、文脈情報を豊富に捉える<br><br>これにより、シーン全体を理解し、画像内の物体だけでなく、<br>その背景や文脈も考慮した高精度なセグメンテーションを実現                           |
| DeepLab | アトラス畳み込み（Atrous Convolution）とAtrous Spatial Pyramid Pooling (ASPP)を導入<br><br>アトラス畳み込みにより、プーリングを使わずに受容野を広げることができ、空間解像度の低下を防ぐ<br>ASPPは、複数の異なるアトラスレートで畳み込みを行い、様々なスケールの特徴を抽出<br> |

## 姿勢推定タスクに使用されるCNN

| モデル名     | 登場年   | 主な特徴と技術登場年                                                                                                      |
| -------- | ----- | --------------------------------------------------------------------------------------------------------------- |
| OpenPose | 2017年 | 1枚の画像から、複数の人物の姿勢を同時に推定<br>関節点を示すヒートマップと、関節点間の接続を示す<br><font color="#ffff00">部位接続（PAFs）</font>を同時に予測する二つのブランチを持つ |
| HRNet    | 2019年 | ネットワーク全体を通して高解像度の特徴表現を維持<br>異なる解像度の並列ストリーム間で情報を繰り返し交換し、<br>高精度のキーポイントヒートマップを生成                                  |
## 

## データ拡張
