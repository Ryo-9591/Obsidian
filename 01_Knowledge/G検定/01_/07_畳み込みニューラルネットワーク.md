# CNN
ディープラーニングの中で最も成功しているモデル

| 項目           | 年代    | 人物                 | 説明                                                                                                                            | 図                                    |
| ------------ | ----- | ------------------ | ----------------------------------------------------------------------------------------------------------------------------- | ------------------------------------ |
| ネオコグニトロン     | 1979年 | 福島邦彦               | 階層的な特徴抽出と位置ずれ不変性<br>S細胞：特徴を抽出する役割<br>C細胞：S細胞層で抽出された特徴の位置のずれを吸収                                                                | ![[Pasted image 20250901190743.png]] |
| LeNet        | 1998年 | ヤン・ルカン             | <font color="#ffff00">手書き数字の認識に使用</font><br><br>畳み込み層とプーリング層を組み合わせることで画像の特徴を効率的に抽出<br><font color="#ffff00">誤差逆伝搬法</font>を用いる | ![[Pasted image 20250901191054.png]] |
| AlexNet      | 2012年 | アレックス・クリジェフスキー     | ILSVRC優勝<br>大規模画像データセットImageNetでの圧倒的な性能<br>GPUの活用、<font color="#ffff00">ReLU</font>、ドロップアウトを導入                                | ![[Pasted image 20250901191937.png]] |
| GoogleNet    | 2014年 | Google             | ILSVRC優勝<br><font color="#ffff00">Inceptionモジュール</font>を導入し、複数の畳み込み層を並列に処理することで、計算量を増やさずに精度を向上                                | ![[Pasted image 20250901192258.png]] |
| VGG          | 2014年 | オックスフォード大学         | 同じサイズの小さな<font color="#ffff00">3x3</font>の畳み込み層を何層も重ねることで、表現力を高めた                                                             | ![[Pasted image 20250901192319.png]] |
| ResNet       | 2015年 | Microsoft Research | <font color="#ffff00">Residual Block</font>（残差ブロック）を導入<br>深いネットワークの学習を困難にしていた<font color="#ffff00">勾配消失問題</font>を解決           | ![[Pasted image 20250901192330.png]] |
| Wide ResNet  | 2016年 | セルゲイ・ザハロフ          | ResNetの残差ブロックの幅（チャネル数）を広げることで、パラメータ数を大幅に増やさずに性能を向上                                                                            | ![[Pasted image 20250901192656.png]] |
| DenseNet     | 2017年 | Gao Huang          | 密な接続（Dense Connectivity）を導入<br><font color="#ffff00">各層が、それより前の全ての層の出力に接続</font>することで、特徴の再利用を促進し、勾配の伝播を改善した。                  | ![[Pasted image 20250901192727.png]] |
| SENET        | 2017年 | Momenta            | ILSVRC優勝<br>SE（Squeeze-and-Excitation）ブロックを導入<br><font color="#ffff00">チャネル方向の情報を動的に重み付け</font>することで、重要な特徴を強調し、精度を向上          | ![[Pasted image 20250901192834.png]] |
| MobileNet    | 2017年 | Google             | Depthwise Separable Convolutionを導入し、計算量を大幅に削減。モバイルデバイスや組み込みシステムでの利用に適した軽量なモデル。                                                |                                      |
| NASNet       | 2018年 | Google             | **「Neural Architecture Search（NAS）」**という手法を用いて、強化学習によって最適なネットワーク構造を自動で探索した最初のモデルの一つ。                                          |                                      |
| MnasNet      | 2018年 | Google             | NASNetを改良し、**モバイルデバイスのレイテンシ（遅延）**を考慮してネットワーク構造を探索。実用的なパフォーマンスと効率を両立した。                                                        |                                      |
| EfficientNet | 2019年 | Google             | **深さ（depth）、幅（width）、解像度（resolution）**の3つの次元をバランス良くスケーリングする**「複合スケーリング」**を提案。高い効率で最高の性能を実現した。                                 |                                      |

## データ拡張
