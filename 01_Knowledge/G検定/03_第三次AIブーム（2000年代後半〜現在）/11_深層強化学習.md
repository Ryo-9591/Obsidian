# 深層強化学習（Deep Reinforcement Learning）
ニューラルネットワーク（深層学習）と強化学習を組み合わせた分野
複雑な環境での意思決定を学習するモデルを構築できる
## DQN (Deep Q-Network)
強化学習のQ学習に、深層学習を組み合わせた最初の成功例です。Q値をニューラルネットワークで近似し、 Atariゲームで人間を超える性能を示しました。
## ダブルDQN（Double DQN）
DQNの課題である<font color="#ffff00">Q値の過大評価を解決した手法</font>です。
学習用と評価用の2つのネットワークを使い分ける
→推定の安定性を向上
## デュエリングネットワーク（Dueling Network）
DQNのアーキテクチャを改良したもの
Q値を、状態の価値（V値）と各行動の優位性（A値）に<font color="#ffff00">分けて学習</font>することで、学習効率を高めた
## Rainbow
DQNの様々な改良手法（ダブルDQN、デュエリングネットワークなど）を組み合わせ、統合したモデル
単一のアルゴリズムで、各手法のメリットを享受できます。
## ノイジーネットワーク（Noisy Network）
ニューラルネットワークのパラメータに<font color="#ffff00">ガウス分布により発生させたノイズを重みとして計算に用いる</font>ことで、探索を促進する手法
→ε-greedy法のような単純な探索手法を必要としなくなる
## APE-X
DQNを分散学習に対応させたモデルです。複数のアクター（エージェント）が同時に環境と相互作用し、データを集めて一つのネットワークを学習させます。これにより、学習速度が劇的に向上しました。
## Agent57
各環境に適応する複数のアルゴリズムを動的に選択する強化学習エージェントです。Atari 57種類のゲームで最高の性能を達成しました。
# 深層生成モデル
